{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cc67392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a92c85ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: dict_keys(['veranstaltungen'])\n",
      "Type of 'veranstaltungen': <class 'dict'>\n",
      "\n",
      "DataFrame shape: (1681, 54)\n",
      "First 10 columns: ['guid', 'course_number', 'course_name', 'course_subtitle', 'district', 'event_type', 'minimum_participants', 'current_participants', 'maximum_participants', 'number_of_sessions']\n",
      "\n",
      "Missing values:\n",
      "contact_person_title                 1618\n",
      "lecturer_title                       1606\n",
      "lecturer                             1526\n",
      "locations_address_latitude           1525\n",
      "locations_address_postal_code        1525\n",
      "locations_address_longitude          1525\n",
      "locations_address_street             1523\n",
      "locations_address_city               1512\n",
      "locations_address_accessible         1502\n",
      "locations_appointments_weekday       1502\n",
      "locations_appointments_start_date    1502\n",
      "locations_address_room               1502\n",
      "locations_appointments_start_time    1502\n",
      "locations_address_facility           1502\n",
      "locations_appointments_end_time      1502\n",
      "merkmale_merkmal_wert                1490\n",
      "merkmale_merkmal_last_name           1490\n",
      "target_group                         1346\n",
      "contact_person_phone                  831\n",
      "course_subtitle                       814\n",
      "category_label                        272\n",
      "locations_address                     183\n",
      "locations_appointments                183\n",
      "price_additional                      178\n",
      "lecturer_salutation                   173\n",
      "lecturer_last_name                    166\n",
      "lecturer_first_name                   166\n",
      "contact_person_salutation               8\n",
      "contact_person_email                    6\n",
      "event_type                              2\n",
      "contact_person_first_name               1\n",
      "contact_person_last_name                1\n",
      "maximum_participants                    0\n",
      "end_date                                0\n",
      "start_date                              0\n",
      "number_of_sessions                      0\n",
      "minimum_participants                    0\n",
      "current_participants                    0\n",
      "description                             0\n",
      "district                                0\n",
      "course_name                             0\n",
      "keywords                                0\n",
      "registration_email                      0\n",
      "category_version                        0\n",
      "category_text                           0\n",
      "registration_phone                      0\n",
      "website_uri                             0\n",
      "website_last_name                       0\n",
      "website_type                            0\n",
      "registration_link                       0\n",
      "price_discount_possible                 0\n",
      "price_amount                            0\n",
      "course_number                           0\n",
      "guid                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Step 1: Load JSON file\n",
    "with open('/Users/apple/Desktop/DSA_project/DSA2025_birds/flask_app/data/courses.json', encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Inspect structure\n",
    "print(\"Top-level keys:\", data.keys())\n",
    "print(\"Type of 'veranstaltungen':\", type(data['veranstaltungen']))\n",
    "\n",
    "# Step 3: Extract actual course list\n",
    "veranstaltung_list = data['veranstaltungen']['veranstaltung']  # <- FIX IS HERE\n",
    "\n",
    "# Step 4: Normalize into DataFrame\n",
    "df_german = pd.json_normalize(veranstaltung_list, sep='_')\n",
    "\n",
    "# Step 5: Explore\n",
    "print(\"\\nDataFrame shape:\", df.shape)\n",
    "print(\"First 10 columns:\", df.columns[:10].tolist())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d13fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1681 entries, 0 to 1680\n",
      "Data columns (total 54 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   guid                               1681 non-null   int64         \n",
      " 1   course_number                      1681 non-null   object        \n",
      " 2   course_name                        1681 non-null   object        \n",
      " 3   course_subtitle                    867 non-null    object        \n",
      " 4   district                           1681 non-null   object        \n",
      " 5   event_type                         1679 non-null   object        \n",
      " 6   minimum_participants               1681 non-null   int64         \n",
      " 7   current_participants               1681 non-null   int64         \n",
      " 8   maximum_participants               1681 non-null   int64         \n",
      " 9   number_of_sessions                 1681 non-null   int64         \n",
      " 10  start_date                         1681 non-null   datetime64[ns]\n",
      " 11  end_date                           1681 non-null   datetime64[ns]\n",
      " 12  target_group                       335 non-null    object        \n",
      " 13  keywords                           1681 non-null   object        \n",
      " 14  description                        1681 non-null   object        \n",
      " 15  category_version                   1681 non-null   float64       \n",
      " 16  category_text                      1681 non-null   object        \n",
      " 17  registration_phone                 1681 non-null   object        \n",
      " 18  registration_email                 1681 non-null   object        \n",
      " 19  registration_link                  1681 non-null   object        \n",
      " 20  contact_person_salutation          1673 non-null   object        \n",
      " 21  contact_person_title               63 non-null     object        \n",
      " 22  contact_person_last_name           1680 non-null   object        \n",
      " 23  contact_person_first_name          1680 non-null   object        \n",
      " 24  contact_person_phone               850 non-null    object        \n",
      " 25  contact_person_email               1675 non-null   object        \n",
      " 26  locations_address                  1498 non-null   object        \n",
      " 27  locations_appointments             1498 non-null   object        \n",
      " 28  price_amount                       1681 non-null   object        \n",
      " 29  price_discount_possible            1681 non-null   bool          \n",
      " 30  price_additional                   1503 non-null   object        \n",
      " 31  lecturer_salutation                1508 non-null   object        \n",
      " 32  lecturer_title                     75 non-null     object        \n",
      " 33  lecturer_last_name                 1515 non-null   object        \n",
      " 34  lecturer_first_name                1515 non-null   object        \n",
      " 35  website_type                       1681 non-null   object        \n",
      " 36  website_last_name                  1681 non-null   object        \n",
      " 37  website_uri                        1681 non-null   object        \n",
      " 38  lecturer                           155 non-null    object        \n",
      " 39  merkmale_merkmal_last_name         191 non-null    object        \n",
      " 40  merkmale_merkmal_wert              191 non-null    object        \n",
      " 41  locations_address_facility         179 non-null    object        \n",
      " 42  locations_address_postal_code      156 non-null    float64       \n",
      " 43  locations_address_city             169 non-null    object        \n",
      " 44  locations_address_street           158 non-null    object        \n",
      " 45  locations_address_room             179 non-null    object        \n",
      " 46  locations_address_longitude        156 non-null    float64       \n",
      " 47  locations_address_latitude         156 non-null    float64       \n",
      " 48  locations_address_accessible       179 non-null    float64       \n",
      " 49  locations_appointments_weekday     179 non-null    object        \n",
      " 50  locations_appointments_start_date  179 non-null    datetime64[ns]\n",
      " 51  locations_appointments_start_time  179 non-null    object        \n",
      " 52  locations_appointments_end_time    179 non-null    object        \n",
      " 53  category_label                     1409 non-null   object        \n",
      "dtypes: bool(1), datetime64[ns](3), float64(5), int64(5), object(40)\n",
      "memory usage: 697.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "df_eng= pd.read_excel(\n",
    "    \"sub_20_eng.xlsx\",\n",
    "    sheet_name=\"sub_20_eng\",\n",
    "    header=0\n",
    "    )\n",
    "\n",
    "df_eng= df.dropna(axis=1, how='all')\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Define the translation mapping (German ‚Üí English column names)\n",
    "column_translation = {\n",
    "    'guid': 'guid',\n",
    "    'nummer': 'course_number',\n",
    "    'name': 'course_name',\n",
    "    'untertitel': 'course_subtitle',\n",
    "    'bezirk': 'district',\n",
    "    'veranstaltungsart': 'event_type',\n",
    "    'minimale_teilnehmerzahl': 'minimum_participants',\n",
    "    'aktuelle_teilnehmerzahl': 'current_participants',\n",
    "    'maximale_teilnehmerzahl': 'maximum_participants',\n",
    "    'anzahl_termine': 'number_of_sessions',\n",
    "    'beginn_datum': 'start_date',\n",
    "    'ende_datum': 'end_date',\n",
    "    'zielgruppe': 'target_group',\n",
    "    'schlagwort': 'keywords',\n",
    "    'text': 'description',\n",
    "    'dvv_kategorie_@version': 'category_version',\n",
    "    'dvv_kategorie_#text': 'category_label',\n",
    "    'anmeldung_telefon': 'registration_phone',\n",
    "    'anmeldung_mail': 'registration_email',\n",
    "    'anmeldung_link': 'registration_link',\n",
    "    'ansprechperson_anrede': 'contact_person_salutation',\n",
    "    'ansprechperson_titel': 'contact_person_title',\n",
    "    'ansprechperson_name': 'contact_person_last_name',\n",
    "    'ansprechperson_vorname': 'contact_person_first_name',\n",
    "    'ansprechperson_telefon': 'contact_person_phone',\n",
    "    'ansprechperson_mail': 'contact_person_email',\n",
    "    'ortetermine_adresse': 'locations_address',\n",
    "    'ortetermine_termin': 'locations_appointments',\n",
    "    'preis_betrag': 'price_amount',\n",
    "    'preis_rabatt_moeglich': 'price_discount_possible',\n",
    "    'preis_zusatz': 'price_additional',\n",
    "    'dozent_anrede': 'lecturer_salutation',\n",
    "    'dozent_titel': 'lecturer_title',\n",
    "    'dozent_name': 'lecturer_last_name',\n",
    "    'dozent_vorname': 'lecturer_first_name',\n",
    "    'webadresse_typ': 'website_type',\n",
    "    'webadresse_name': 'website_last_name',\n",
    "    'webadresse_uri': 'website_uri',\n",
    "    'dozent': 'lecturer',\n",
    "    'merkmale_merkmal_name': 'merkmale_merkmal_last_name',\n",
    "    'merkmale_merkmal_wert': 'merkmale_merkmal_wert',\n",
    "    'ortetermine_adresse_lehrstaette': 'locations_address_facility',\n",
    "    'ortetermine_adresse_plz': 'locations_address_postal_code',\n",
    "    'ortetermine_adresse_ort': 'locations_address_city',\n",
    "    'ortetermine_adresse_strasse': 'locations_address_street',\n",
    "    'ortetermine_adresse_raum': 'locations_address_room',\n",
    "    'ortetermine_adresse_laengengrad': 'locations_address_longitude',\n",
    "    'ortetermine_adresse_breitengrad': 'locations_address_latitude',\n",
    "    'ortetermine_adresse_behindertenzugang': 'locations_address_accessible',\n",
    "    'ortetermine_termin_wochentag': 'locations_appointments_weekday',\n",
    "    'ortetermine_termin_beginn_datum': 'locations_appointments_start_date',\n",
    "    'ortetermine_termin_beginn_uhrzeit': 'locations_appointments_start_time',\n",
    "    'ortetermine_termin_ende_uhrzeit': 'locations_appointments_end_time'\n",
    "}\n",
    "\n",
    "# Step 2: Filter and rename columns in df_german\n",
    "available_cols = [col for col in column_translation if col in df_german.columns]\n",
    "df_german_renamed = df_german[available_cols].rename(columns={k: column_translation[k] for k in available_cols})\n",
    "\n",
    "# Step 3: Ensure guid is string type in both DataFrames\n",
    "df_eng['guid'] = df_eng['guid'].astype(str)\n",
    "df_german_renamed['guid'] = df_german_renamed['guid'].astype(str)\n",
    "\n",
    "# Step 4: Merge on 'guid'\n",
    "df_merged = df_eng.merge(df_german_renamed, on='guid', how='left', suffixes=('', '_de'))\n",
    "\n",
    "# Step 5: Overwrite all columns from df_german EXCEPT 'course_name' and 'category_label'\n",
    "protected = ['course_name', 'category_label']\n",
    "\n",
    "for col in df_german_renamed.columns:\n",
    "    if col == 'guid' or col in protected:\n",
    "        continue\n",
    "    if f\"{col}_de\" in df_merged.columns:\n",
    "        df_merged[col] = df_merged[f\"{col}_de\"]\n",
    "\n",
    "# Step 6: Drop all helper *_de columns\n",
    "df_merged.drop(columns=[col for col in df_merged.columns if col.endswith('_de')], inplace=True)\n",
    "\n",
    "#also bring the course name in german\n",
    "df_merged = df_merged.merge(df_german[['guid', 'name']].rename(columns={'name': 'course_name_german'}), on='guid', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c821200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>course_number</th>\n",
       "      <th>course_name</th>\n",
       "      <th>course_subtitle</th>\n",
       "      <th>district</th>\n",
       "      <th>event_type</th>\n",
       "      <th>minimum_participants</th>\n",
       "      <th>current_participants</th>\n",
       "      <th>maximum_participants</th>\n",
       "      <th>number_of_sessions</th>\n",
       "      <th>...</th>\n",
       "      <th>locations_address_room</th>\n",
       "      <th>locations_address_longitude</th>\n",
       "      <th>locations_address_latitude</th>\n",
       "      <th>locations_address_accessible</th>\n",
       "      <th>locations_appointments_weekday</th>\n",
       "      <th>locations_appointments_start_date</th>\n",
       "      <th>locations_appointments_start_time</th>\n",
       "      <th>locations_appointments_end_time</th>\n",
       "      <th>category_label</th>\n",
       "      <th>course_name_german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604369</td>\n",
       "      <td>FK3.840</td>\n",
       "      <td>Body Percussion ' the Rhythmic Sound of the Body'</td>\n",
       "      <td>None</td>\n",
       "      <td>Friedrichshain-Kreuzberg</td>\n",
       "      <td>Kurs</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bodypercussion -  der rhythmische K√∂rperklang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610723</td>\n",
       "      <td>FK4.D-ik-179-5a</td>\n",
       "      <td>German B1.1</td>\n",
       "      <td>Aufbaumodul 5</td>\n",
       "      <td>Friedrichshain-Kreuzberg</td>\n",
       "      <td>Kurs</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foreign Languages</td>\n",
       "      <td>Deutsch B1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656403</td>\n",
       "      <td>SZ810-29-04-01</td>\n",
       "      <td>German Integration Course A1.1</td>\n",
       "      <td>Basissprachkurs Modul 1</td>\n",
       "      <td>Steglitz-Zehlendorf</td>\n",
       "      <td>Kurs</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foreign Languages</td>\n",
       "      <td>Deutsch Integrationskurs A1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658796</td>\n",
       "      <td>Mi404-B192S-13</td>\n",
       "      <td>German Orientation Course</td>\n",
       "      <td>None</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Kurs</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foreign Languages</td>\n",
       "      <td>Deutsch Orientierungskurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683442</td>\n",
       "      <td>Sp4.224.W9</td>\n",
       "      <td>German Literacy W9</td>\n",
       "      <td>Deutsch Alphabetisierung-Integrationskurs</td>\n",
       "      <td>Spandau</td>\n",
       "      <td>Kurs</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foreign Languages</td>\n",
       "      <td>Deutsch Alphabetisierung W9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     guid    course_number                                        course_name  \\\n",
       "0  604369          FK3.840  Body Percussion ' the Rhythmic Sound of the Body'   \n",
       "1  610723  FK4.D-ik-179-5a                                        German B1.1   \n",
       "2  656403   SZ810-29-04-01                     German Integration Course A1.1   \n",
       "3  658796   Mi404-B192S-13                          German Orientation Course   \n",
       "4  683442       Sp4.224.W9                                 German Literacy W9   \n",
       "\n",
       "                             course_subtitle                  district  \\\n",
       "0                                       None  Friedrichshain-Kreuzberg   \n",
       "1                              Aufbaumodul 5  Friedrichshain-Kreuzberg   \n",
       "2                    Basissprachkurs Modul 1       Steglitz-Zehlendorf   \n",
       "3                                       None                     Mitte   \n",
       "4  Deutsch Alphabetisierung-Integrationskurs                   Spandau   \n",
       "\n",
       "  event_type minimum_participants current_participants maximum_participants  \\\n",
       "0       Kurs                    8                    0                   10   \n",
       "1       Kurs                   12                    1                   20   \n",
       "2       Kurs                    8                    6                   12   \n",
       "3       Kurs                    8                    5                   16   \n",
       "4       Kurs                   10                    1                   16   \n",
       "\n",
       "  number_of_sessions  ... locations_address_room locations_address_longitude  \\\n",
       "0                 10  ...                    NaN                         NaN   \n",
       "1                100  ...                    NaN                         NaN   \n",
       "2                100  ...                    NaN                         NaN   \n",
       "3                100  ...                    NaN                         NaN   \n",
       "4                100  ...                    NaN                         NaN   \n",
       "\n",
       "  locations_address_latitude locations_address_accessible  \\\n",
       "0                        NaN                          NaN   \n",
       "1                        NaN                          NaN   \n",
       "2                        NaN                          NaN   \n",
       "3                        NaN                          NaN   \n",
       "4                        NaN                          NaN   \n",
       "\n",
       "  locations_appointments_weekday locations_appointments_start_date  \\\n",
       "0                            NaN                               NaN   \n",
       "1                            NaN                               NaN   \n",
       "2                            NaN                               NaN   \n",
       "3                            NaN                               NaN   \n",
       "4                            NaN                               NaN   \n",
       "\n",
       "  locations_appointments_start_time locations_appointments_end_time  \\\n",
       "0                               NaN                             NaN   \n",
       "1                               NaN                             NaN   \n",
       "2                               NaN                             NaN   \n",
       "3                               NaN                             NaN   \n",
       "4                               NaN                             NaN   \n",
       "\n",
       "      category_label                             course_name_german  \n",
       "0                NaN  Bodypercussion -  der rhythmische K√∂rperklang  \n",
       "1  Foreign Languages                                   Deutsch B1.1  \n",
       "2  Foreign Languages                 Deutsch Integrationskurs A1.1   \n",
       "3  Foreign Languages                      Deutsch Orientierungskurs  \n",
       "4  Foreign Languages                    Deutsch Alphabetisierung W9  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(5)  # German / raw DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b6e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- locations_appointments ---\n",
      "Type: locations_appointments\n",
      "<class 'list'>     1498\n",
      "<class 'float'>     183\n",
      "Name: count, dtype: int64\n",
      "Sample: [\"[{'wochentag': 'Samstag', 'beginn_datum': '2025-03-29', 'beginn_uhrzeit': '11:00', 'ende_uhrzeit': '16:00'}, {'wochentag': 'Samstag', 'beginn_datum': '2025-03-29', 'beginn_uhrzeit': '11:00', 'ende_uhrzeit': '16:00'}, {'wochentag': 'Sonntag', 'beginn_datum': '2025-03-30', 'beginn_uhrzeit': '11:00', 'ende_uhrzeit': '15:00'}, {'wochentag': 'Sonntag', 'beginn_datum': '2025-03-30', 'beginn_uhrzeit': '11:00', 'ende_uhrzeit': '15:00'}]\", \"[{'wochentag': 'Montag', 'beginn_datum': '2025-05-05', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-05-06', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-05-08', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-05-12', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-05-13', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-05-15', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-05-19', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-05-20', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-05-22', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-05-26', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-05-27', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Montag', 'beginn_datum': '2025-06-02', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-06-03', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-06-05', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Freitag', 'beginn_datum': '2025-06-06', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-06-10', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-06-12', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Freitag', 'beginn_datum': '2025-06-13', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-06-16', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-06-17', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-06-19', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-06-23', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-06-24', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-06-26', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Montag', 'beginn_datum': '2025-06-30', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-07-01', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-07-03', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Dienstag', 'beginn_datum': '2025-07-08', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '21:15'}, {'wochentag': 'Donnerstag', 'beginn_datum': '2025-07-10', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}, {'wochentag': 'Freitag', 'beginn_datum': '2025-07-11', 'beginn_uhrzeit': '18:00', 'ende_uhrzeit': '20:30'}]\"]\n",
      "\n",
      "--- registration_email ---\n",
      "Type: registration_email\n",
      "<class 'str'>    1681\n",
      "Name: count, dtype: int64\n",
      "Sample: ['vhs@ba-fk.berlin.de', 'vhs@ba-fk.berlin.de']\n",
      "\n",
      "--- keywords ---\n",
      "Type: keywords\n",
      "<class 'list'>    1681\n",
      "Name: count, dtype: int64\n",
      "Sample: [\"['Fragen auf Englisch', 'GESUNDHEIT', 'KULTUR', 'MUSIK', 'Wochenendkurs']\", \"['B1', 'BAMF Kursbeginn √ºbermittelt', 'BAMF Kursplanung aktualisieren √ºbermittelt', 'BAMF Kursplanung √ºbermittelt', 'Deutsch Fremdsprache', 'Intensivkurs', 'Migrant:innen', 'vhs.cloud']\"]\n",
      "\n",
      "--- contact_person_first_name ---\n",
      "Type: contact_person_first_name\n",
      "<class 'str'>      1680\n",
      "<class 'float'>       1\n",
      "Name: count, dtype: int64\n",
      "Sample: ['Claudia', 'Karla']\n",
      "\n",
      "--- contact_person_last_name ---\n",
      "Type: contact_person_last_name\n",
      "<class 'str'>      1680\n",
      "<class 'float'>       1\n",
      "Name: count, dtype: int64\n",
      "Sample: ['Hiesemann', 'Grunfeld']\n",
      "\n",
      "--- keywords ---\n",
      "Type: keywords\n",
      "<class 'list'>    1681\n",
      "Name: count, dtype: int64\n",
      "Sample: [\"['Fragen auf Englisch', 'GESUNDHEIT', 'KULTUR', 'MUSIK', 'Wochenendkurs']\", \"['B1', 'BAMF Kursbeginn √ºbermittelt', 'BAMF Kursplanung aktualisieren √ºbermittelt', 'BAMF Kursplanung √ºbermittelt', 'Deutsch Fremdsprache', 'Intensivkurs', 'Migrant:innen', 'vhs.cloud']\"]\n",
      "\n",
      "--- description ---\n",
      "Type: description\n",
      "<class 'list'>    1681\n",
      "Name: count, dtype: int64\n",
      "Sample: [\"[{'eigenschaft': 'Beschreibung', 'text': 'Bodypercussion vereint Musik und K√∂rpergef√ºhl ‚Äì sie f√∂rdert die Konzentration und die Koordinationsf√§higkeit. Wir entdecken und formen unsere rhythmischen F√§higkeiten auf spielerische und sehr lebendige Weise. Beginnend mit Bewegungsspielen und grundlegenden rhythmischen √úbungen, erlernen Sie im  Anschluss die Grundfiguren der Bodypercussion. Mit der  Stimme und dem gesamten K√∂rper erschaffen und spielen wir einfache und etwas komplexere Rhythmusmuster, die wir auf einpr√§gsame Weise festigen und kreativ ausbauen.\\\\r\\\\nDieser Kurs richtet sich an alle, die ihre rhythmischen F√§higkeiten entdecken und sich f√ºr die klangvollen M√∂glichkeiten ihres K√∂rpers sensibilisieren m√∂chten.  \\\\r\\\\nVorkenntnisse sind nicht erforderlich.   \\\\r\\\\nBitte kommen Sie in bewegungsfreundlicher Kleidung und bequemen Schuhen.\\\\r\\\\n'}, {'eigenschaft': 'Zusatzinformation', 'text': None}]\", \"[{'eigenschaft': 'Beschreibung', 'text': 'Voraussetzung: Kenntnisse im Umfang der abgeschlossenen Stufe A2\\\\r\\\\n\\\\r\\\\nDieser Deutschkurs ist einer von 7 Kursabschnitten eines Integrationskurses nach ¬ß43 des Aufenthaltsgesetzes.\\\\r\\\\n\\\\r\\\\nLehrmaterial: wird im Kurs bekannt gegeben \\\\r\\\\n\\\\r\\\\nDer Kurs wird auf der Lernplattform vhs.cloud begleitet. Den Kursschl√ºssel erhalten Sie in der ersten Unterrichtsstunde. '}, {'eigenschaft': 'Zusatzinformation', 'text': 'Entgelt bei einer F√∂rderung durch das Bundesamt: ‚Ç¨ 229,-/ 220,-/ 195,- /  0,-\\\\r\\\\nEntgelt ohne F√∂rderung: ‚Ç¨ 235,-'}]\"]\n"
     ]
    }
   ],
   "source": [
    "# Show data types and sample values for key nested fields\n",
    "nested_cols = [\n",
    "    'locations_appointments', \n",
    "    'registration_email', 'keywords',\n",
    "    'contact_person_first_name', \n",
    "    'contact_person_last_name',\n",
    "    'keywords', \n",
    "    'description'\n",
    "]\n",
    "\n",
    "for col in nested_cols:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(\"Type:\", df_merged[col].map(type).value_counts())\n",
    "    print(\"Sample:\", df_merged[col].dropna().astype(str).iloc[:2].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# Helper functions\n",
    "# ----------------------------\n",
    "\n",
    "def safe_parse(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x) if isinstance(x, str) else x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def extract_description(x):\n",
    "    x = safe_parse(x)\n",
    "    if isinstance(x, list):\n",
    "        for entry in x:\n",
    "            if isinstance(entry, dict) and entry.get(\"eigenschaft\") == \"Beschreibung\":\n",
    "                return entry.get(\"text\", \"\")\n",
    "    return str(x)\n",
    "\n",
    "def flatten_keywords(x):\n",
    "    x = safe_parse(x)\n",
    "    if isinstance(x, list):\n",
    "        return ', '.join(map(str, x))\n",
    "    return str(x)\n",
    "\n",
    "def extract_first(x, key):\n",
    "    x = safe_parse(x)\n",
    "    if isinstance(x, list) and x and isinstance(x[0], dict):\n",
    "        return x[0].get(key)\n",
    "    return None\n",
    "\n",
    "# ----------------------------\n",
    "# Apply transformations\n",
    "# ----------------------\n",
    "# Clean description and keywords\n",
    "df_merged['description_clean'] = df_merged['description'].apply(extract_description)\n",
    "df_merged['keywords_clean'] = df_merged['keywords'].apply(flatten_keywords)\n",
    "\n",
    "# Extract from locations_appointments (only first entry)\n",
    "df_merged['course_weekday'] = df_merged['locations_appointments'].apply(lambda x: extract_first(x, 'wochentag'))\n",
    "\n",
    "df_merged['course_start_time'] = pd.to_datetime(\n",
    "    df_merged['locations_appointments'].apply(lambda x: extract_first(x, 'beginn_uhrzeit')),\n",
    "    format='%H:%M', errors='coerce'\n",
    ").dt.time\n",
    "\n",
    "df_merged['course_end_time'] = pd.to_datetime(\n",
    "    df_merged['locations_appointments'].apply(lambda x: extract_first(x, 'ende_uhrzeit')),\n",
    "    format='%H:%M', errors='coerce'\n",
    ").dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "412deae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1352/1352 [18:34<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# Define translation function\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        if pd.isna(text):\n",
    "            return None\n",
    "        return GoogleTranslator(source='de', target='en').translate(text)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Optional: deduplicate and cache to avoid repeated translations\n",
    "unique_names = df_merged['course_name_german'].dropna().unique()\n",
    "translation_map = {name: translate_to_english(name) for name in tqdm(unique_names)}\n",
    "\n",
    "# Apply to DataFrame\n",
    "df_merged['course_name_translated'] = df_merged['course_name_german'].map(translation_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db101d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3af51364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53/53 [00:04<00:00, 11.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# 1. Load German-compatible model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 2. Prepare search text for all courses (if not already done)\n",
    "df_merged['search_text'] = (\n",
    "    df_merged['course_name_german'].fillna('') + ' ' + df_merged['course_subtitle'].fillna('')+ ' ' +\n",
    "    df_merged['keywords_clean'].fillna('') \n",
    ")\n",
    "\n",
    "# 3. Embed the full catalog (one-time step)----should be done for the whole dataset in the dataprep stage\n",
    "course_embeddings = model.encode(df_merged['search_text'].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2acc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langdetect import detect\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "\n",
    "\n",
    "def translate_query_to_german(query):\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='de').translate(query)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Translation failed: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3d445bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Search tokens: ['junge', 'erwachsene', 'kommunikationskurse']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name_translated</th>\n",
       "      <th>course_name_german</th>\n",
       "      <th>semantic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>English B1 - Communicate Successfully (presenc...</td>\n",
       "      <td>Englisch B1 - Communicate Successfully (Pr√§sen...</td>\n",
       "      <td>0.646069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>English B1 conversation course - for generatio...</td>\n",
       "      <td>Englisch B1 Konversationskurs - f√ºr die Genera...</td>\n",
       "      <td>0.643940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Young VHS: Letting keyboard on the PC - presen...</td>\n",
       "      <td>junge vhs: Tastaturschreiben am PC - Pr√§senzku...</td>\n",
       "      <td>0.642837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>The art of the professional small talk</td>\n",
       "      <td>Die Kunst des beruflichen Smalltalks</td>\n",
       "      <td>0.614358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Criticizing, de -escalating, motivating: know ...</td>\n",
       "      <td>Kritisieren, deeskalieren, motivieren: Know ho...</td>\n",
       "      <td>0.595090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Communicate in groups, teams and projects</td>\n",
       "      <td>Kommunizieren in Gruppen, Teams und Projekten</td>\n",
       "      <td>0.575896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Skillfully counterattack - handling of regular...</td>\n",
       "      <td>Gekonnt kontern - Umgang mit Stammtischparolen...</td>\n",
       "      <td>0.569097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Learn to sew after pattern template</td>\n",
       "      <td>N√§hen lernen nach Schnittmustervorlage</td>\n",
       "      <td>0.567704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Building course non -violent communication</td>\n",
       "      <td>Aufbaukurs Gewaltfreie Kommunikation</td>\n",
       "      <td>0.556180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>English A2/B1 for generation 55+ - A New Chall...</td>\n",
       "      <td>Englisch A2/B1 f√ºr die Generation 55+ - A new ...</td>\n",
       "      <td>0.552874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 course_name_translated  \\\n",
       "61    English B1 - Communicate Successfully (presenc...   \n",
       "64    English B1 conversation course - for generatio...   \n",
       "1057  Young VHS: Letting keyboard on the PC - presen...   \n",
       "797              The art of the professional small talk   \n",
       "301   Criticizing, de -escalating, motivating: know ...   \n",
       "1255          Communicate in groups, teams and projects   \n",
       "1005  Skillfully counterattack - handling of regular...   \n",
       "985                 Learn to sew after pattern template   \n",
       "1332         Building course non -violent communication   \n",
       "63    English A2/B1 for generation 55+ - A New Chall...   \n",
       "\n",
       "                                     course_name_german  semantic_score  \n",
       "61    Englisch B1 - Communicate Successfully (Pr√§sen...        0.646069  \n",
       "64    Englisch B1 Konversationskurs - f√ºr die Genera...        0.643940  \n",
       "1057  junge vhs: Tastaturschreiben am PC - Pr√§senzku...        0.642837  \n",
       "797                Die Kunst des beruflichen Smalltalks        0.614358  \n",
       "301   Kritisieren, deeskalieren, motivieren: Know ho...        0.595090  \n",
       "1255      Kommunizieren in Gruppen, Teams und Projekten        0.575896  \n",
       "1005  Gekonnt kontern - Umgang mit Stammtischparolen...        0.569097  \n",
       "985              N√§hen lernen nach Schnittmustervorlage        0.567704  \n",
       "1332               Aufbaukurs Gewaltfreie Kommunikation        0.556180  \n",
       "63    Englisch A2/B1 f√ºr die Generation 55+ - A new ...        0.552874  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_query = \"Young adults communication classes\"\n",
    "\n",
    "try:\n",
    "    matches = get_course_matchesv3(user_query, df_merged, model, course_embeddings, top_n=10)\n",
    "    display(matches[['course_name_translated', 'course_name_german', 'semantic_score']])\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "220ec49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_matchesv3(user_query, df, model, course_embeddings, top_n=30, similarity_threshold=0.45):\n",
    "    import numpy as np\n",
    "    from langdetect import detect\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    if not isinstance(user_query, str) or not user_query.strip():\n",
    "        raise ValueError(\"Invalid input. Please provide a non-empty search query.\")\n",
    "\n",
    "    # Detect language and translate if needed\n",
    "    try:\n",
    "        detected_lang = detect(user_query)\n",
    "    except Exception:\n",
    "        detected_lang = \"en\"\n",
    "\n",
    "    translated_query = user_query if detected_lang == 'de' else translate_query_to_german(user_query)\n",
    "\n",
    "\n",
    "    # Split into distinct tokens\n",
    "    search_tokens = translated_query.lower().split()\n",
    "    print(f\"üîé Search tokens: {search_tokens}\")\n",
    "\n",
    "    from rapidfuzz import fuzz\n",
    "    \n",
    "    # Fuzzy token match: retain rows where any token matches\n",
    "    def fuzzy_token_match(text):\n",
    "        if pd.isna(text): return False\n",
    "        text = text.lower()\n",
    "        return any(fuzz.partial_ratio(token, text) >= 50 for token in search_tokens)\n",
    "\n",
    "    df_filtered = df[\n",
    "        df['course_name_german'].apply(fuzzy_token_match) |\n",
    "        df['course_name_translated'].apply(fuzzy_token_match)\n",
    "    ]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        raise ValueError(\"No courses matched any extracted keyword tokens. Try a different query.\")\n",
    "\n",
    "    # Compute semantic score on filtered subset\n",
    "    query_embedding = model.encode([translated_query])\n",
    "    filtered_embeddings = model.encode(df_filtered['search_text'].tolist())\n",
    "    similarities = cosine_similarity(query_embedding, filtered_embeddings)[0]\n",
    "\n",
    "    df_filtered = df_filtered.copy()\n",
    "    df_filtered['semantic_score'] = similarities\n",
    "    df_filtered = df_filtered[similarities >= similarity_threshold]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        raise ValueError(\"Courses matched the keywords, but were semantically too distant.\")\n",
    "\n",
    "    return df_filtered.sort_values(by='semantic_score', ascending=False).head(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "189445ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "\n",
    "# -- Time parsing helper --\n",
    "def parse_time(t):\n",
    "    try:\n",
    "        return datetime.strptime(t, \"%H:%M\").time() if isinstance(t, str) else t\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -- Time penalty calculation (0-10 scale) --\n",
    "def compute_time_penalty(actual, preferred, window_minutes=60):\n",
    "    if actual is None or preferred is None:\n",
    "        return 10  # Max penalty\n",
    "    diff = (datetime.combine(datetime.today(), actual) - datetime.combine(datetime.today(), preferred)).total_seconds() / 60\n",
    "    if diff < -window_minutes or diff > window_minutes:\n",
    "        return 10\n",
    "    return abs(diff) / window_minutes * 10\n",
    "\n",
    "# -- Budget penalty calculation (0-10 scale) --\n",
    "def compute_budget_penalty(course_price, user_budget, allowance_pct=0.3):\n",
    "    try:\n",
    "        course_price = float(course_price)\n",
    "    except:\n",
    "        return 10\n",
    "    if pd.isna(course_price) or user_budget <= 0:\n",
    "        return 10\n",
    "    low = user_budget * (1 - allowance_pct)\n",
    "    high = user_budget * (1 + allowance_pct)\n",
    "    if course_price < low or course_price > high:\n",
    "        return 10\n",
    "    return abs(course_price - user_budget) / (user_budget * allowance_pct) * 10\n",
    "\n",
    "# -- Main filter and rank function --\n",
    "def filter_and_rank_courses(user_prefs, df):\n",
    "    filtered_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        appointments = row['locations_appointments']\n",
    "        if not isinstance(appointments, list):\n",
    "            continue\n",
    "\n",
    "        best_penalty = None\n",
    "        for appt in appointments:\n",
    "            weekday = appt.get('wochentag')\n",
    "            start_time = parse_time(appt.get('beginn_uhrzeit'))\n",
    "            end_time = parse_time(appt.get('ende_uhrzeit'))\n",
    "\n",
    "            # Weekday filter\n",
    "            if user_prefs.get('preferred_days') and weekday not in user_prefs['preferred_days']:\n",
    "                continue\n",
    "\n",
    "            # Time boundary filters\n",
    "            if user_prefs.get('Time_start'):\n",
    "                min_start = (datetime.combine(datetime.today(), user_prefs['Time_start']) - timedelta(minutes=60)).time()\n",
    "                if start_time and start_time < min_start:\n",
    "                    continue\n",
    "            if user_prefs.get('Time_end'):\n",
    "                max_end = (datetime.combine(datetime.today(), user_prefs['Time_end']) + timedelta(minutes=60)).time()\n",
    "                if end_time and end_time > max_end:\n",
    "                    continue\n",
    "\n",
    "            # Penalties\n",
    "            start_penalty = compute_time_penalty(start_time, user_prefs.get('Time_start'))\n",
    "            end_penalty = compute_time_penalty(end_time, user_prefs.get('Time_end'))\n",
    "            price = row.get('price_amount')\n",
    "            budget_penalty = compute_budget_penalty(price, user_prefs.get('budget'))\n",
    "\n",
    "            total_score = 0.6 * budget_penalty + 0.2 * start_penalty + 0.2 * end_penalty\n",
    "\n",
    "            if best_penalty is None or total_score < best_penalty['score']:\n",
    "                best_penalty = {\n",
    "                    'score': total_score,\n",
    "                    'start_penalty': start_penalty,\n",
    "                    'end_penalty': end_penalty,\n",
    "                    'budget_penalty': budget_penalty,\n",
    "                    'matched_appt': appt\n",
    "                }\n",
    "\n",
    "        if best_penalty and row['district'] == user_prefs.get('district'):\n",
    "            result = row.to_dict()\n",
    "            result.update(best_penalty)\n",
    "            filtered_rows.append(result)\n",
    "\n",
    "    if not filtered_rows:\n",
    "        raise ValueError(\"No courses matched the filters you have selected.\")\n",
    "\n",
    "    ranked_df = pd.DataFrame(filtered_rows)\n",
    "    ranked_df = ranked_df.sort_values(by='score', ascending=True)\n",
    "    return ranked_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Creative sewing workshop for young adults\"\n",
    "from datetime import time\n",
    "\n",
    "user_preferences = {\n",
    "    'district': '',\n",
    "    'budget': 100.0,\n",
    "    'preferred_days': ['Samstag', 'Sonntag'],  # Saturday, Sunday\n",
    "    'Time_start': time(10, 0),   # Preferred starting after 10:00\n",
    "    'Time_end': time(15, 0),     # Preferred ending before 15:00\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e9949773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Search tokens: ['kreativer', 'n√§hwerkstatt', 'f√ºr', 'junge', 'erwachsene']\n",
      "‚ùå No courses matched the filters you have selected.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Step 1: Semantic matches\n",
    "    df_semantic = get_course_matchesv3(user_query, df_merged, model, course_embeddings, top_n=100)\n",
    "\n",
    "    # Step 2: Structured filter + ranking\n",
    "    final_matches = filter_and_rank_courses(user_preferences, df_semantic)\n",
    "\n",
    "    # Step 3: Review detailed time matching results\n",
    "    display(final_matches[[\n",
    "        'course_name_translated',\n",
    "        'district',\n",
    "        'price_amount',\n",
    "        'matched_appt',\n",
    "        'budget_penalty',\n",
    "        'start_penalty',\n",
    "        'end_penalty',\n",
    "        'score'\n",
    "    ]].head(10))\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1867f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assuming df_merged is already loaded\n",
    "# df_merged = pd.read_csv(\"your_path_here.csv\")\n",
    "df_merged['maximum_participants'] = pd.to_numeric(df_merged['maximum_participants'], errors='coerce')\n",
    "df_merged['current_participants'] = pd.to_numeric(df_merged['current_participants'], errors='coerce')\n",
    "df_merged['minimum_participants'] = pd.to_numeric(df_merged['minimum_participants'], errors='coerce')\n",
    "\n",
    "# Apply transformations\n",
    "df_merged['prop_occupancy_left'] = (df_merged['maximum_participants'] - df_merged['current_participants']) / df_merged['maximum_participants']\n",
    "df_merged['prop_minimum_to_reach'] = (df_merged['minimum_participants'] - df_merged['current_participants']) / df_merged['minimum_participants']\n",
    "df_merged['prop_minimum_to_reach'] = df_merged['prop_minimum_to_reach'].clip(lower=0)\n",
    "\n",
    "np.random.seed(42)\n",
    "df_merged['number_of_women'] = df_merged['current_participants'].apply(lambda x: np.random.randint(0, x + 1) if x > 0 else 0)\n",
    "df_merged['percent_women'] = np.where(df_merged['current_participants'] > 0,\n",
    "                                      df_merged['number_of_women'] / df_merged['current_participants'], 0)\n",
    "df_merged['prop_men'] = np.where(df_merged['current_participants'] > 0,\n",
    "                                 (df_merged['current_participants'] - df_merged['number_of_women']) / df_merged['current_participants'], 0)\n",
    "\n",
    "df_merged['sponsored'] = np.random.choice([1, 0], size=len(df_merged), p=[0.25, 0.75])\n",
    "df_merged['gap_to_80_percent_women'] = 0.8 - df_merged['percent_women']\n",
    "df_merged['gap_to_80_percent_men'] = 0.8 - df_merged['prop_men']\n",
    "\n",
    "# One-hot encode target groups\n",
    "if 'target_group' in df_merged.columns:\n",
    "    target_groups = df_merged['target_group'].dropna().unique()\n",
    "    for group in target_groups:\n",
    "        col = f\"target_group_{group}\"\n",
    "        df_merged[col] = df_merged['target_group'].apply(lambda x: 1 if x == group else 0)\n",
    "\n",
    "# Ensure price is numeric\n",
    "df_merged['price_amount'] = pd.to_numeric(df_merged.get('price_amount', np.nan), errors='coerce')\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "df_merged.to_csv(\"df_merged_preprocessed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "333d6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"course_embeddings.npy\", course_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "63631622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model_paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['locations_appointments'] = df_merged['locations_appointments'].apply(safe_parse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6e10d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame\n",
    "df_merged.to_csv(\"df_merged_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "64d9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (centralized)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langdetect import detect\n",
    "from rapidfuzz import fuzz\n",
    "import ast\n",
    "import itertools, pulp\n",
    "\n",
    "# Translation (simple wrapper)\n",
    "from deep_translator import GoogleTranslator\n",
    "def translate_query_to_german(query):\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='de').translate(query)\n",
    "    except:\n",
    "        return query\n",
    "\n",
    "# -----------------------\n",
    "# Class 1: CourseMatcher\n",
    "# -----------------------\n",
    "class CourseMatcher:\n",
    "    def __init__(self, df, model, embeddings):\n",
    "        self.df = df[df['prop_occupancy_left'] > 0].copy()\n",
    "        self.model = model\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_time(t):\n",
    "        try:\n",
    "            return datetime.strptime(t, \"%H:%M\").time() if isinstance(t, str) else t\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def compute_time_penalty(self, actual, preferred):\n",
    "        if actual is None or preferred is None:\n",
    "            return 0\n",
    "        diff = (datetime.combine(datetime.today(), actual) - datetime.combine(datetime.today(), preferred)).total_seconds() / 60\n",
    "        return 10 if abs(diff) > 60 else abs(diff) / 60 * 10\n",
    "\n",
    "    def compute_budget_penalty(self, course_price, user_budget):\n",
    "        try:\n",
    "            course_price = float(course_price)\n",
    "        except:\n",
    "            return 0 if user_budget is None else 10\n",
    "        if pd.isna(course_price) or not user_budget:\n",
    "            return 0\n",
    "        low, high = user_budget * 0.7, user_budget * 1.3\n",
    "        if course_price < low or course_price > high:\n",
    "            return 10\n",
    "        return abs(course_price - user_budget) / (user_budget * 0.3) * 10\n",
    "\n",
    "    def filter_by_prefs(self, user_prefs):\n",
    "        def is_valid_appt(appt):\n",
    "            weekday = appt.get('wochentag')\n",
    "            start = self.parse_time(appt.get('beginn_uhrzeit'))\n",
    "            end = self.parse_time(appt.get('ende_uhrzeit'))\n",
    "            if user_prefs.get('preferred_days') and weekday not in user_prefs['preferred_days']:\n",
    "                return False\n",
    "            if user_prefs.get('Time_start') and start and start < (datetime.combine(datetime.today(), user_prefs['Time_start']) - timedelta(minutes=60)).time():\n",
    "                return False\n",
    "            if user_prefs.get('Time_end') and end and end > (datetime.combine(datetime.today(), user_prefs['Time_end']) + timedelta(minutes=60)).time():\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        filtered = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            if user_prefs.get('district') and row.get('district') != user_prefs['district']:\n",
    "                continue\n",
    "            if self.compute_budget_penalty(row.get('price_amount'), user_prefs.get('budget')) == 10:\n",
    "                continue\n",
    "            if any(is_valid_appt(appt) for appt in row.get('locations_appointments', [])):\n",
    "                filtered.append(row)\n",
    "        return pd.DataFrame(filtered)\n",
    "\n",
    "    def get_matches(self, user_query, user_prefs=None, top_n=20, similarity_threshold=0.45):\n",
    "        if not isinstance(user_query, str) or not user_query.strip():\n",
    "            raise ValueError(\"Empty or invalid search query.\")\n",
    "\n",
    "        translated = user_query if detect(user_query) == 'de' else translate_query_to_german(user_query)\n",
    "        tokens = translated.lower().split()\n",
    "\n",
    "        def fuzzy_match(text): return any(fuzz.partial_ratio(t, str(text).lower()) >= 50 for t in tokens)\n",
    "\n",
    "        df_filtered = self.filter_by_prefs(user_prefs or {})\n",
    "        df_filtered = df_filtered[df_filtered['course_name_german'].apply(fuzzy_match) | df_filtered['course_name_translated'].apply(fuzzy_match)]\n",
    "\n",
    "        if df_filtered.empty:\n",
    "            backup = self.df[self.df['course_name_german'].apply(fuzzy_match) | self.df['course_name_translated'].apply(fuzzy_match)]\n",
    "            if backup.empty:\n",
    "                raise ValueError(\"No courses match your keywords.\")\n",
    "            raise ValueError(\"No results match your filters. Try disabling filters.\")\n",
    "\n",
    "        query_emb = self.model.encode([translated])\n",
    "        emb_filtered = self.model.encode(df_filtered['search_text'].tolist())\n",
    "        sim = cosine_similarity(query_emb, emb_filtered)[0]\n",
    "\n",
    "        df_filtered['semantic_score'] = sim\n",
    "        df_filtered = df_filtered[sim >= similarity_threshold]\n",
    "        if df_filtered.empty:\n",
    "            raise ValueError(\"Results were too semantically distant.\")\n",
    "\n",
    "        top_df = df_filtered.sort_values(by='semantic_score', ascending=False).head(top_n).copy()\n",
    "        avg_sem = top_df['semantic_score'].mean()\n",
    "\n",
    "        rows = []\n",
    "        for _, row in top_df.iterrows():\n",
    "            appt = next((a for a in row['locations_appointments'] if isinstance(a, dict)), {})\n",
    "            penalties = 0.6 * self.compute_budget_penalty(row['price_amount'], user_prefs.get('budget')) + \\\n",
    "                        0.2 * self.compute_time_penalty(self.parse_time(appt.get('beginn_uhrzeit')), user_prefs.get('Time_start')) + \\\n",
    "                        0.2 * self.compute_time_penalty(self.parse_time(appt.get('ende_uhrzeit')), user_prefs.get('Time_end'))\n",
    "            scaled = (penalties / 10) * avg_sem\n",
    "            deviation = avg_sem - scaled\n",
    "            final_score = 0.7 * row['semantic_score'] + 0.3 * deviation\n",
    "            rows.append({**row.to_dict(), \"final_score_user\": final_score})\n",
    "        return pd.DataFrame(rows).sort_values(by='final_score_user', ascending=False)\n",
    "\n",
    "# -----------------------\n",
    "# Class 2: PlatformPreferenceRanker\n",
    "# -----------------------\n",
    "class PlatformPreferenceRanker:\n",
    "    def __init__(self, df, gender, selected_groups):\n",
    "        self.df = df.copy()\n",
    "        self.gender_col = 'gap_to_80_percent_women' if gender == 'female' else 'gap_to_80_percent_men'\n",
    "        if gender == 'female' and \"Women\" not in selected_groups:\n",
    "            selected_groups.append(\"Women\")\n",
    "        self.selected = [f\"target_group_{g}\" for g in selected_groups]\n",
    "\n",
    "    def rank(self):\n",
    "        df = self.df.copy()\n",
    "        df['numeric_score'] = df[['prop_occupancy_left', 'prop_minimum_to_reach', self.gender_col]].sum(axis=1)\n",
    "        df['rank_index'] = df['numeric_score'].rank(ascending=False)\n",
    "        df['binary_sum'] = df[self.selected + ['sponsored']].sum(axis=1)\n",
    "        max_score = df['numeric_score'].max()\n",
    "        min_score = df['numeric_score'].min()\n",
    "        df['weight'] = df.apply(lambda r: ((max_score - r['numeric_score']) / r['rank_index']) * 1.05 if r['rank_index'] > 0 else ((max_score - min_score)/len(df)) * 1.05, axis=1)\n",
    "        df['binary_boost'] = df['weight'] * df['binary_sum']\n",
    "        df['final_score_platform'] = df['numeric_score'] + df['binary_boost']\n",
    "        return df.sort_values(by='final_score_platform', ascending=False)\n",
    "\n",
    "# -----------------------\n",
    "# Class 3: ConsensusRanker\n",
    "# -----------------------\n",
    "class ConsensusRanker:\n",
    "    def __call__(self, user_df, plat_df):\n",
    "        guids = list(user_df['guid'])\n",
    "        u_ranks = {g: i for i, g in enumerate(user_df['guid'])}\n",
    "        p_ranks = {g: i for i, g in enumerate(plat_df['guid'])}\n",
    "        w_user, w_plat = 0.5, 0.5\n",
    "\n",
    "        margins = {}\n",
    "        for i, j in itertools.combinations(guids, 2):\n",
    "            vote = w_user * (u_ranks[i] < u_ranks[j]) + w_plat * (p_ranks[i] < p_ranks[j])\n",
    "            if vote > 0.5: margins[(i, j)] = 1\n",
    "            elif vote < 0.5: margins[(j, i)] = 1\n",
    "            else: margins[(i, j)], margins[(j, i)] = 0.1, 0.1\n",
    "\n",
    "        model = pulp.LpProblem(\"KemenyConsensus\", pulp.LpMinimize)\n",
    "        x = pulp.LpVariable.dicts('x', (guids, guids), 0, 1, cat='Binary')\n",
    "        model += pulp.lpSum(w * x[j][i] for (i, j), w in margins.items())\n",
    "        for i, j in itertools.permutations(guids, 2): model += x[i][j] + x[j][i] == 1\n",
    "        for i, j, k in itertools.permutations(guids, 3): model += x[i][j] + x[j][k] + x[k][i] >= 1\n",
    "        model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "\n",
    "        ordered = sorted(guids, key=lambda g: sum(x[g][h].value() for h in guids if h != g), reverse=True)\n",
    "        return ordered\n",
    "\n",
    "# -----------------------\n",
    "# Final Pipeline Wrapper\n",
    "# -----------------------\n",
    "class CourseSelectionPipeline:\n",
    "    def __init__(self, df, model, embeddings):\n",
    "        self.df = df\n",
    "        self.model = model\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def run(self, user_query, user_prefs, gender, target_groups):\n",
    "        matcher = CourseMatcher(self.df, self.model, self.embeddings)\n",
    "        user_df = matcher.get_matches(user_query, user_prefs)\n",
    "        plat_df = PlatformPreferenceRanker(user_df, gender, target_groups).rank()\n",
    "        final_ids = ConsensusRanker()(user_df, plat_df)\n",
    "        return {\n",
    "            \"final_guids\": final_ids,\n",
    "            \"user_df\": user_df,\n",
    "            \"platform_df\": plat_df\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "98730e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Df used for our data\n",
    "\n",
    "df_merged = pd.read_csv(\"df_merged_preprocessed.csv\")\n",
    "\n",
    "#Load Embeddings for our model\n",
    "\n",
    "course_embeddings = np.load(\"course_embeddings.npy\")\n",
    "\n",
    "#load sentence transformer model\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"saved_model_paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e9a30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[257]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m user_target_groups = [\u001b[33m\"\u001b[39m\u001b[33mPeople with a migration background\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Assuming CourseSelectionPipeline has been defined and instantiated\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_prefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_prefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgender\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_target_groups\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 180\u001b[39m, in \u001b[36mCourseSelectionPipeline.run\u001b[39m\u001b[34m(self, user_query, user_prefs, gender, target_groups)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_query, user_prefs, gender, target_groups):\n\u001b[32m    179\u001b[39m     matcher = CourseMatcher(\u001b[38;5;28mself\u001b[39m.df, \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     user_df = \u001b[43mmatcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     plat_df = PlatformPreferenceRanker(user_df, gender, target_groups).rank()\n\u001b[32m    182\u001b[39m     final_ids = ConsensusRanker()(user_df, plat_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mCourseMatcher.get_matches\u001b[39m\u001b[34m(self, user_query, user_prefs, top_n, similarity_threshold)\u001b[39m\n\u001b[32m     82\u001b[39m tokens = translated.lower().split()\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfuzzy_match\u001b[39m(text): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(fuzz.partial_ratio(t, \u001b[38;5;28mstr\u001b[39m(text).lower()) >= \u001b[32m50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m df_filtered = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilter_by_prefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prefs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m df_filtered = df_filtered[df_filtered[\u001b[33m'\u001b[39m\u001b[33mcourse_name_german\u001b[39m\u001b[33m'\u001b[39m].apply(fuzzy_match) | df_filtered[\u001b[33m'\u001b[39m\u001b[33mcourse_name_translated\u001b[39m\u001b[33m'\u001b[39m].apply(fuzzy_match)]\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_filtered.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mCourseMatcher.filter_by_prefs\u001b[39m\u001b[34m(self, user_prefs)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_budget_penalty(row.get(\u001b[33m'\u001b[39m\u001b[33mprice_amount\u001b[39m\u001b[33m'\u001b[39m), user_prefs.get(\u001b[33m'\u001b[39m\u001b[33mbudget\u001b[39m\u001b[33m'\u001b[39m)) == \u001b[32m10\u001b[39m:\n\u001b[32m     72\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_valid_appt(appt) \u001b[38;5;28;01mfor\u001b[39;00m appt \u001b[38;5;129;01min\u001b[39;00m row.get(\u001b[33m'\u001b[39m\u001b[33mlocations_appointments\u001b[39m\u001b[33m'\u001b[39m, [])):\n\u001b[32m     74\u001b[39m         filtered.append(row)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(filtered)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_budget_penalty(row.get(\u001b[33m'\u001b[39m\u001b[33mprice_amount\u001b[39m\u001b[33m'\u001b[39m), user_prefs.get(\u001b[33m'\u001b[39m\u001b[33mbudget\u001b[39m\u001b[33m'\u001b[39m)) == \u001b[32m10\u001b[39m:\n\u001b[32m     72\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43mis_valid_appt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m appt \u001b[38;5;129;01min\u001b[39;00m row.get(\u001b[33m'\u001b[39m\u001b[33mlocations_appointments\u001b[39m\u001b[33m'\u001b[39m, [])):\n\u001b[32m     74\u001b[39m         filtered.append(row)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(filtered)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mCourseMatcher.filter_by_prefs.<locals>.is_valid_appt\u001b[39m\u001b[34m(appt)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_valid_appt\u001b[39m(appt):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     weekday = \u001b[43mappt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mwochentag\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     57\u001b[39m     start = \u001b[38;5;28mself\u001b[39m.parse_time(appt.get(\u001b[33m'\u001b[39m\u001b[33mbeginn_uhrzeit\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     58\u001b[39m     end = \u001b[38;5;28mself\u001b[39m.parse_time(appt.get(\u001b[33m'\u001b[39m\u001b[33mende_uhrzeit\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Run your pipeline\n",
    "pipeline = CourseSelectionPipeline(df_merged, model, course_embeddings)\n",
    "# Example user preferences dictionary\n",
    "user_prefs = {\n",
    "    'budget': 100,  # in euros\n",
    "    'preferred_days': ['Samstag', 'Sonntag'],  # course weekdays\n",
    "    'district': 'Neuk√∂lln'  # location filter\n",
    "}\n",
    "\n",
    "# User metadata\n",
    "user_query = \"english courses for adults\"\n",
    "user_gender = \"female\"\n",
    "user_target_groups = [\"People with a migration background\"]\n",
    "\n",
    "# Assuming CourseSelectionPipeline has been defined and instantiated\n",
    "results = pipeline.run(\n",
    "    user_query=user_query,\n",
    "    user_prefs=user_prefs,\n",
    "    gender=user_gender,\n",
    "    target_groups=user_target_groups\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
